1. 数据库设计（必须）
需设计多层级 FAQ 结构化存储表：
类目表：存储一级 / 二级类目 ID、名称、状态（启用 / 禁用）、创建时间，建立类目层级关联；
FAQ 基础表：存储 FAQ ID、所属类目 ID、标准回答、生效 / 失效时间、审核状态；
提问表：关联 FAQ ID，存储待选提问、相似提问文本及对应的相似度阈值；
向量存储表（算法侧）：存储提问文本的 BERT 编码向量，加速相似度检索。
2. 模型选择
核心使用BERT-base-chinese（中文适配版）：该模型能捕捉中文语义特征，适配短文本（用户提问）的编码与相似度计算；暂无需大模型（如 GPT），因场景聚焦 “相似提问匹配”，BERT 的语义编码能力已满足需求，且推理速度快、部署成本低；仅当需生成个性化回答时，可叠加大模型做回答优化。
3. BERT 的使用方式
预处理：对用户提问、历史 FAQ 提问做统一清洗（去特殊符号、分词），通过 BERT 的 Tokenizer 转为输入 ID 和注意力掩码；
编码：将文本输入 BERT 模型，提取[CLS]位置的向量作为文本语义表征；
集成：后端将编码逻辑封装为接口，接收用户提问文本，返回编码向量供相似度计算调用。
