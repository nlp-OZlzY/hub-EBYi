### 如何使用BERT进行文本编码，并且使用BERT进行相似度计算

**1. 文本编码机制 (Text Encoding)** 我们选用 `bert-base-chinese` 作为基座模型，处理流程如下：

- **Input 格式化**：对输入文本（用户提问或标准FAQ）进行 Tokenization。必须在句首添加 `[CLS]` 标记，句尾添加 `[SEP]` 标记。
- **Mask 机制**：由于输入必须是定长 Tensor（如 `seq_len=64`），对于短文本进行补零（Padding）。**关键点**：必须生成 `Attention Mask` 向量（1为真实词，0为填充），强制模型在计算 Attention 时忽略 Padding 部分，避免噪音干扰。
- **模型推断**：数据经过 BERT 的 12 层 Transformer Encoder，输出 `Last Hidden State`，维度为 `[Batch_Size, Seq_Len, 768]`。

**2. 句向量生成策略 (Pooling Strategy)** 这是一个关键的技术决策点。

- **方案**：不直接使用 `[CLS]` 向量（该向量更适合分类任务），而是采用 **Mean Pooling（平均池化）** 策略。
- **实现**：取最后一层输出中所有有效 Token（即 Mask=1 的部分）对应的向量，计算其平均值。
- **产出**：获得一个能够表征整句话语义的 **768 维固定向量**。

**3. 相似度计算 (Similarity Calculation)** 在向量空间中，我们采用**余弦相似度 (Cosine Similarity)** 作为度量标准。相比欧氏距离，余弦相似度更关注向量在空间中的方向一致性，对文本长度不敏感。

- **计算公式**：

$$Similarity = \cos(\theta) = \frac{A \cdot B}{\|A\| \times \|B\|}$$

**判定逻辑**： 计算得分范围为 `[-1, 1]`。工程上需设定置信度阈值（建议 **Threshold = 0.85**）：

- **Score ≥ 0.85**：判定为命中，返回对应的标准问题及答案。

- **Score < 0.85**：判定为未命中，触发兜底回复或转人工逻辑。

  

#### 以下为逻辑流程图：

![deepseek_mermaid_20260212_ef1c81](D:\Data\Chrome Download\deepseek_mermaid_20260212_ef1c81.svg)
