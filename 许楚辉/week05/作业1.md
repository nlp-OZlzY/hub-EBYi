-  **需要设计数据库吗？**
   - 需要设计数据库，不同级别的类目，一个类目里面对应有什么FAQ，这些数据都是需要持久性保存的。
   - 像分级类目，包括类目的一些创建信息，这些都是结构化的，比如时间，类型，都是可以规定或者是结构化的，可以使用关系型数据库，如使用MySQL这样的经典数据库，数据一致性强，通用性也很好。**MySQL 作为核心元数据存储。** 鉴于FAQ管理涉及严格的层级关系（类目）和事务性操作（增删改查），关系型数据库是最佳选择。 具体的表结构设计应包含 `category` 表（存储类目树）和 `faq_content` 表（存储问答详情）。
   - 此外还需要**Vector DB（向量型）**：如 Milvus 或 ES (Dense Vector)。MySQL 中的文本数据经模型计算后，生成的**高维向量**（Embeddings）存储于此，用于毫秒级的相似度检索。

-  **模型选择方案**
   - **核心模型**：我们将使用 **BERT（Bidirectional Encoder Representations from Transformers）** 及其变体（如 RoBERTa 或 Sentence-BERT）。相比传统的关键词匹配（如 BM25），BERT 能解决“词不达意”的问题（例如识别“无法登陆”与“账号被锁”的语义相似性）。
   - **辅助策略**：为了保证响应速度，建议结合**倒排索引**（关键词匹配）作为第一层粗排，BERT 作为第二层精排。

-  **BERT 的具体应用逻辑** 
   - 我们不是将 BERT 用于分类任务，而是用于**语义特征提取（Feature Extraction）**：
   - **离线阶段（Indexing）**：将库里的“标准问题”和“相似问法”输入 BERT，取其 `[CLS]` 标记或平均池化层输出，转化为固定维度的向量（如 768 维），存入向量数据库。
   - **在线阶段（Serving）**：用户提问时，实时调用 BERT 将提问转化为向量。
   - **匹配计算**：计算“用户提问向量”与“库中问题向量”的**余弦相似度（Cosine Similarity）**。得分超过阈值（如 0.85）的最相似问题，其对应的答案即为返回结果。

-  **是否需要使用大模型**
   - 如果仅是需要返回针对该提问的标准答案，BERT的准确率与成本是足够应对当前需要的，性价比十分高。
   - 但是如果要求回答更具拓展性和人性化，可以引入大模型架构。
