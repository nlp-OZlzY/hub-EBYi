作业1：客服工作台 作业 https://help.aliyun.com/zh/document_detail/421160.html?spm=a2c4g.11186623.0.0.30f638fe8lQYuY 功能1: faq 类目管理，一级类目，二级类目， 对应的faq 信息 https://help.aliyun.com/zh/document_detail/421161.html?spm=a2c4g.11186623.0.0.30f67558YDiTwC 功能2: faq录入和管理，待选提问、相似提问、生效时间、对应回答
使用场景：代替人工客服，用户的提问直接与历史的提问进行相似度匹配，最相似的提问的回答返回给用户。 作业1（400字文档）: 
阅读上面的客服工作台的说明，总结我们自己作为后端开发和算法开发的角色，我们需要做什么？需要设计数据库吗？ 需要使用什么模型？ 如何使用使用bert的？ 是否需要使用大模型

作为后端开发：
1.数据库设计  设计类目分类表，FAQ信息表
2.API设计及开发  实现类目管理、FAQ增删改查、相似度匹配等核心接口
3.业务逻辑实现  处理FAQ录入规则、生效时间控制、权限管理等功能
4.系统集成  与前端界面对接

作为算法开发：
1. 文本相似度计算：基于BERT模型实现用户提问与历史FAQ的语义匹配
2. 模型训练优化：针对客服场景预训练模型
3. 性能调优：平衡准确率与响应速度，优化检索效率
4. 效果评估：建立评估体系持续优化匹配效果

是否需要设计数据库：
需要，需要数据库存储类目树结构、FAQ内容、用户提问记录、匹配日志等信息

所用模型：
语义匹配模型 BERT模型

是否需要使用大模型：
不需要使用大模型，但是现阶段BERT已足够满足需求，大模型成本较高且响应较慢。


作业2（400字文档， 流程图）: 如何使用bert 进行文本编码，并且使用bert 进行相似度计算，需要写清楚技术方案；

一、文本预处理
1. 分词处理：使用jieba进行中文分词
2. 文本清洗：去除特殊符号、停用词过滤
3. 长度控制：截断过长文本，补齐短文本
二、BERT编码
1. 加载预训练模型：选用`bert-base-chinese`
2. Tokenization：转换文本为token序列
3. 添加特殊标记：[CLS]开头，[SEP]分隔
4. 获取句向量：提取[CLS]位置的隐藏状态作为句子表示
三、相似度计算
1. 向量归一化：对所有向量进行L2标准化
2. 余弦相似度：计算用户提问与FAQ问题的相似度分数
3. Top-K检索：选取相似度最高的K个候选答案
4. 阈值过滤：设定最低相似度门槛确保回答质量

