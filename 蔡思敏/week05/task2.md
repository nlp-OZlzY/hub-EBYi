如何使用bert 进行文本编码，并且使用bert 进行相似度计算

**bert模型**：设计主要用于联合编码两个句子，不适合直接计算句子相似度，效率较低。
**sbert(sentence-bert)模型**：可以通过孪生结构独立的编码两个句子，生成句子向量，支持高效的句子余弦相似度计算。

<img src="sbert相似度计算流程图.png" alt="流程图" width="1000" />

## 1. 准备环境
- 安装相关的库： sentence_transformers
- 选择预训练模型

## 2. 文本预处理
- 清洗文本：去除特殊字符、标点符号，统一大小写

## 3. 文本编码
- 将一条或多条数据输入到sbert模型中，生成固定维度的向量表示
- 对知识库进行批量编码，生成向量并存储，以便后续检索

## 4. 相似度计算
**小规模场景**
- 实时编码用户输入的问题文本，并与知识库中的向量逐一对比
- 计算余弦相似度，按得分返回top-k的结果

**大规模场景**
- 使用FAISS构建向量索引，加快检索过程
- 将知识库向量一次性加载至索引，查询时一次索引检索，返回最相似的向量，毫秒级

## 5. 结果过滤
- 设置相似度阈值，低于阈值视为无匹配
- 返回匹配的结果和相似度分数
- 未匹配到的，可通过llm+RAG构建动态prompt进行回答


