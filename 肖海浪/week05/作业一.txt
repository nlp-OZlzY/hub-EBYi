# 客服工作台后端与算法开发任务总结

​	目标是把常见问题沉淀为FAQ知识库，让用户提问时优先由系统自助解答，从而替代部分人工客服。作为后端开发，需要提供FAQ类目树与FAQ内容的管理能力，包括一级/二级（或多级）类目、FAQ标准问法/标题、相似问法、答案、生效时间、标签与关联问题等字段，并提供增删改查接口、权限控制、操作审计与发布生效机制；同时在查询侧要支持按类目/标签/生效时间过滤，保证过期知识不被命中。
 	作为算法开发，核心是“问句相似度匹配”：将FAQ标准问法与相似问法用BERT编码为向量并离线入库；在线对用户问题同样编码，在向量库中检索TopK并按余弦相似度排序，若最高分超过阈值则返回对应FAQ答案，否则触发兜底策略（引导追问、转人工，或可选接入大模型做RAG总结与改写）。因此本场景不强制需要大模型，BERT检索即可完成主流程，大模型更适合在未命中时提升体验

## 一、数据库设计

首先需要设计三个表，FAQ类目标，FAQ信息表，用户提问日志表。

1. **FAQ类目表**（faq_category）：

   存储运营侧的管理需求，方便后面培训和任务查询优化的作用。

   用户侧的导航需求，方便用户后续操作，以便于了解这些FAQ信息

   - id, name, parent_id（树形结构支持多级类目）
   - sort_order, create_time

   

2. **FAQ信息表**（faq_entry）

   业务价值：存储FAQ的“完整知识”，方便后续培训
   生效时间控制，可以在特定的时间内运行FAQ，方便工作
   标签分类，可以看很多方面信息内容。

   - id, category_id, question（标准问题）
   - answer, similar_questions（JSON数组）
   - effective_time, expire_time, status
   - question_embedding（768维向量）

   

3. **用户提问日志表**（user_query_log）

   识别FAQ盲区，可以知道用户经常想要知道信息FAQ。
   监控相似度分布和响应时间。

   - id, user_id, query_text

   - matched_faq_id, similarity_score

   - response_time

     

## 二、模型选择

### 核心模型：BERT

- 使用预训练的中文BERT模型：bert-base-chinese
- 主要作用：将文本编码为768维向量表示
- 优势：捕获深层语义关系，而非表层关键词匹配

### 是否需要大模型？

**暂不需要**，原因如下：

- FAQ匹配是典型的相似度计算任务，BERT已能很好地处理
- 大模型成本高，且FAQ回答需要精确、可控
- 未来可考虑用大模型优化答案生成，但当前阶段BERT足够



## 三、BERT使用方案

### 技术路径

1. **离线预处理**：
   - 批量处理所有FAQ问题，生成embedding向量
   - 使用CLS Token或对Token层进行平均池化得到句子向量
2. **在线匹配**：
   - 用户提问 → BERT编码 → 向量检索
   - 计算余弦相似度，返回Top-K匹配结果
   - 设置相似度阈值（如0.75）确保质量
3. **相似提问扩展**：
   - 使用BERT识别用户提问的语义变体
   - 将高频匹配的新问题自动加入相似提问库

### 性能优化

- 使用FAISS或Milvus进行向量检索加速

- 建立缓存机制，相同问题直接返回

- BERT模型量化（FP16/INT8）降低推理延迟

  

## 四、开发分工

- **后端开发**：数据库设计与API开发

  - CRUD接口实现
  - 向量存储与检索集成
  - 缓存策略设计

  

- **算法开发**：模型训练与优化

  - BERT模型微调（可选，使用FAQ数据微调提升领域适配性）
  - embedding生成脚本
  - 相似度计算优化
  - 阈值调优与评估指标设计（准确率、召回率）

  